{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MiniBooNE_PID.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/I-CHIEN/DNN_IC/blob/master/MiniBooNE_PID.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH-rhnkduNG9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from __future__ import print_function\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVGyz6YxuoVt",
        "colab_type": "code",
        "outputId": "235c462b-040c-485c-fa65-8f752b262fd7",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9exACQjZuwtC",
        "colab_type": "code",
        "outputId": "2ea1fa89-8b1a-48d1-e259-286698768b26",
        "cellView": "form",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-39d0df80-58d8-4432-b125-b65f2c0678fb\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-39d0df80-58d8-4432-b125-b65f2c0678fb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving MiniBooNE_PID.txt to MiniBooNE_PID (5).txt\n",
            "User uploaded file \"MiniBooNE_PID.txt\" with length 91174877 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7P_P46ZvqCv",
        "colab_type": "code",
        "outputId": "4bbfbbb2-155e-44e6-a617-37508c996b34",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "\n",
        "import math\n",
        "fp = open('MiniBooNE_PID (5).txt', \"r\")\n",
        "line = fp.readline()\n",
        "line_replace=line.replace(\" \", \",\")\n",
        "line_split=line_replace.split(',')\n",
        "line_split[len(line_split)-1]=line_split[len(line_split)-1].replace('\\n','')\n",
        "line_split.pop(0)\n",
        "data = line_split\n",
        "size_signal = int(data[0])\n",
        "size_background = int(data[1])\n",
        "print('size signal : ' + str(size_signal) + '\\n')\n",
        "print('size background : ' + str(size_background) + '\\n')\n",
        "## 用 while 逐行讀取檔案內容，直至檔案結尾\n",
        "signal_data = []\n",
        "background_data = []\n",
        "index = 0\n",
        "while line:\n",
        "    if index%10000 == 0:\n",
        "        print(index)\n",
        "    line = fp.readline()\n",
        "    line_replace = line.replace(\" \", \",\")\n",
        "    line_split = line_replace.split(',')\n",
        "    line_split[len(line_split) - 1] = line_split[len(line_split) - 1].replace('\\n', '')\n",
        "    line_split.pop(0)\n",
        "\n",
        "    data_split = line_split\n",
        "    data = []\n",
        "    for i in range(0, len(data_split)):\n",
        "        if len(data_split[i]) >= 1:\n",
        "            value = float(data_split[i])\n",
        "            if value > 0:\n",
        "                value = math.log10(value+10)\n",
        "            elif value < 0:\n",
        "                value = math.log10(value*(-1.0)+10)*(-1.0)\n",
        "            data.append(value)\n",
        "    if index < size_signal:\n",
        "        signal_data.append(data)\n",
        "    elif index >= size_signal and index < (size_signal+size_background):\n",
        "        background_data.append(data)\n",
        "    else:\n",
        "        break\n",
        "    index=index+1\n",
        "fp.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "size signal : 36499\n",
            "\n",
            "size background : 93565\n",
            "\n",
            "0\n",
            "10000\n",
            "20000\n",
            "30000\n",
            "40000\n",
            "50000\n",
            "60000\n",
            "70000\n",
            "80000\n",
            "90000\n",
            "100000\n",
            "110000\n",
            "120000\n",
            "130000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99U-v3aRHRUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import shuffle\n",
        "signal_data = shuffle(signal_data,random_state = 0)\n",
        "background_data = shuffle(background_data,random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fftBvUZq8SvH",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "train_data_images = []\n",
        "train_data_labels = []\n",
        "\n",
        "for i in range(0,size_signal-6235):\n",
        "    train_data_images.append(signal_data[i])\n",
        "    train_data_labels.append(1)\n",
        "for i in range(0,size_background-15765):\n",
        "    train_data_images.append(background_data[i])\n",
        "    train_data_labels.append(0)\n",
        "train_data_images, train_data_labels = shuffle(train_data_images, train_data_labels, random_state=0)\n",
        "    \n",
        "    \n",
        "test_data_images = []\n",
        "test_data_labels = []\n",
        "for i in range(size_signal-6235,size_signal):\n",
        "    test_data_images.append(signal_data[i])\n",
        "    test_data_labels.append(1)\n",
        "for i in range(size_background-15765,size_background):\n",
        "    test_data_images.append(background_data[i])\n",
        "    test_data_labels.append(0)\n",
        "test_data_images, test_data_labels = shuffle(test_data_images, test_data_labels, random_state=0)\n",
        "    \n",
        "valid_data_images = test_data_images\n",
        "valid_data_labels = test_data_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAlei3tq8p7u",
        "colab_type": "code",
        "outputId": "4c817529-e7c4-422d-a811-177e1ab2d52e",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "\n",
        "for i in range(0,10):\n",
        "    print(train_data_images[i])\n",
        "    print(train_data_labels[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.1208390331204041, 1.010539007271361, 2.1111448482867465, 1.010884969352206, 1.0008899471311994, 1.014439258442291, 1.054645989221148, 1.0375235857713836, 1.1153748305004538, 1.0103439352116117, 1.147348547803959, 2.558575382467401, 1.0405058590663174, 1.008408741961306, 1.1393547843130618, 3.484558914829348, 1.0761086261937527, 1.3466169921788635, 1.0102709461566755, 1.039591211754706, 1.0531971856516313, 1.0163189222150717, 2.4481495716859465, 1.1647429506449427, 1.0201213598555565, 1.014705599495774, 1.405827693987607, 1.0558406699822844, 1.0062279065791542, 1.0128267256145764, 1.2242968167471864, 1.0522913886956196, 1.010617757466386, 2.393797996211242, 1.003996619416125, 1.0142625735596213, 1.0237197642193643, -1.1578914494553252, 1.0636417974227246, 1.0033851918545729, 2.2906333021841454, 1.3895948492323211, -1.0136010795079153, 1.0924385072083351, 0.0, 1.0056349106474605, 1.00766901765579, 1.0499812446129746, 1.0017705224645594, 1.0103360897947018]\n",
            "0\n",
            "[1.1363802893739599, 1.0278112640629584, 1.4224453792655953, 1.0105423559287894, 1.0009101520230828, 1.0129070435259098, 1.0640984242979457, 1.037240707666987, 1.1221440908369944, 1.0075046671727237, 1.1561889070264602, 2.113237886287634, 1.035069063998417, 1.015781897369596, 1.104412673961013, 3.132041847111938, 1.0350535202862794, 1.3528729797319854, 1.0100863618658567, 1.0535985166774167, 1.0103039857203198, 1.01486699608595, 2.160795554463833, 1.1462976875959683, 1.0204957770766263, 1.0100199075893947, 1.5484754085266064, 1.0578292189245018, 1.006532186893617, -1.0020514793259037, 1.1880722628698628, 1.0552032019911657, 1.0202199481847671, 2.6337440945861332, 1.0058902097833968, 1.0127939195915352, 1.042227307318493, -1.1465779177926083, 1.0535992844196054, 1.0032258893950667, 2.1571393179688543, 1.160907405924963, 1.0240062836355694, 1.148656012995, 1.0001821830612048, 1.0064736583812461, -1.0005489962908083, 1.0411099859044195, -1.00342068548627, 1.0109269406125414]\n",
            "1\n",
            "[1.218412078727354, 1.0640901807780663, 2.1446302419922376, 1.0161760148200323, 1.0001641635524958, 1.0062450306822548, 1.030007658115589, 1.0315808146580436, 1.1333341669086776, 1.0071566842417232, 1.1541186118518802, 2.5674968911042226, 1.027110537294122, 1.0121164570537886, 1.0577326500671786, 2.765643971356728, 1.0070839265933984, 1.7993846660172892, 1.011264172820306, 1.024471669891514, -1.0547382695691556, 1.0111041408215893, 1.5628196474609575, 1.0781046720333214, 1.014443711401242, -1.032378623896021, 2.1996208103230908, 1.0679125785688648, 1.0077868968714838, -1.0240521831668719, 1.334578391864823, 1.019650455718472, 1.0724546774608599, 2.3783161223215163, 1.0006012681926741, 1.0101363868249078, 1.0095333699230353, -1.0849225031434986, 1.057539447910072, 1.0034291997345235, 2.2961801767035803, -1.9159556718107178, -1.0085920818873977, 1.149228660868814, 0.0, 1.0139806112770904, -1.0247364844714841, 1.1964152438199922, 1.145564017395996, 1.0095490896430155]\n",
            "0\n",
            "[1.1956774691715621, 1.0715274341397834, 2.1668443758319493, 1.0150524126825609, 0.0, 1.007136690988032, 1.032718258484803, 1.0326598517055934, 1.1267883611599971, 1.0066661139201856, 1.1570606754052992, 2.5578030469409496, 1.0205127205861246, 1.0291238132060565, 1.0681925431483341, 2.7681650768307966, 1.0088175200737453, 1.8913802134919944, 1.0103615762801044, 1.0470574709899587, -1.1007870612166781, 1.0100896715831353, 1.59141746710346, 1.1122372370330726, 1.0112584176003754, -1.0274653634298054, 2.171939892759559, 1.0632736722034108, 1.0068102606766582, -1.0331310308440729, 1.2870035964995197, 1.0282608326794234, 1.0717704749960535, 2.264385673887848, 1.0019353187979143, 1.0130536012383131, 1.0271317534408144, -1.0850339225116532, 1.045134352297872, 1.0026786458025374, 2.242628377871038, -1.8635161673759626, 1.0094104390859282, 1.1580260852074895, 0.0, 1.0110018096407916, -1.0349695425705014, 1.1035598320424667, -1.0063801589771249, 1.0097029853855988]\n",
            "0\n",
            "[1.164994007760601, 1.0442629466470534, 2.0664563805038054, 1.0142090286810634, 1.0000807165512076, 1.0060060884342952, 1.0296695468263664, 1.036349467916772, 1.1166024314850294, 1.0067365042228569, 1.14452999760575, 1.7326052258289266, 1.0296420452106656, 1.0004541690999371, 1.1132860682879224, 2.9590719350348147, 1.016245424489649, 1.4949000495228608, 1.0093434562429748, 1.0297399965603524, 1.0580770060791258, 1.0171730427242753, 1.6643467053613394, 1.1658963171795422, 1.017942609548604, 1.0126004907846837, 2.0569581824718792, 1.0703814701087002, 1.0099966079930083, 1.0199754677707027, 1.242531738553679, 1.048395186256204, 1.0356497916748717, 2.6656053783602793, 1.0024350897452279, 1.0112535509945981, -1.0121352932538648, -1.1228954678272955, 1.05480909388003, 1.0027690745807931, 2.130992752495096, -1.5741354858976955, 1.064361759875386, 1.0795202253296325, 0.0, 1.0069073435546778, 1.0230099691802979, 1.1137475415812605, 1.1054120742293951, 1.0102913045932476]\n",
            "0\n",
            "[1.1536505632865128, 1.028101488973164, 2.671100608628098, 1.010960650211325, 1.0003454550090154, 0.0, 1.0584541160236873, 1.0363066474853282, 1.1171741486971707, 1.0096114106087557, 1.1543016108317465, -1.0225856043395773, 1.0277151991309796, 1.0090233600538365, 1.1046014741241146, 3.087032110535597, 1.0242400864348713, 1.3165238753737991, 1.009739338105826, 1.0649455479552308, 1.0418271570561113, 1.0145005036277221, 2.1992119695755226, 1.1339347023426956, 1.0203563926632255, 1.008311568104382, 1.451988956747786, 1.0622739207237493, 1.0063805441418174, 1.0164678456000205, 1.2526656859182048, 1.0602017060676006, 1.0234392689910496, 2.6204015495679385, 1.0034060393822783, 1.0149215509389398, 1.015150061288911, -1.1208452804692248, 1.0492021240990381, 1.0053561259371557, 2.178997079683305, -1.2415225738202877, 1.0390046581985444, 1.0907044658339424, 0.0, 1.008615925295635, 1.0233432197543797, 1.1105371877907102, 1.0415300584109672, 1.0101824606970298]\n",
            "1\n",
            "[1.2004291265478242, 1.1952305450291925, 1.5491860198317255, 1.0140469248207227, 0.0, 1.005672977181233, 1.0267396177232657, 1.0305736149426121, 1.1255983630316149, 1.0039619001176854, 1.154882980902188, 1.9959973942686413, -1.0372283108499645, 1.0108732370031035, 1.058040530955234, 2.325534134852827, 1.002568092805829, 1.1429291826871644, 1.011227989839269, 1.038108084057973, 1.0170037310984057, 1.0152399725470056, 1.478712197869985, 1.1193743470718545, 1.0197972868908698, 1.0056013424557586, 2.007024062218519, 1.0648830901868218, 1.0051624022179444, -1.0286437917049644, 1.331473861730969, 1.0404444149037286, 1.0647327058987526, 2.6631032416353433, 1.0004477048276306, 1.0140964536328578, 1.0035942811061462, -1.0789738209058213, 1.0393890919876225, 1.0055383575829486, 2.1278657671374064, -1.485998094624362, 1.119348282530472, 1.1227841862173424, 0.0, 1.0117705450850134, 1.0334288222263495, 1.2300573689544498, 1.1009857044327185, 1.006786403437833]\n",
            "1\n",
            "[1.1837548434560945, 1.063447454181467, 2.182748377362115, 1.0183123721871654, 0.0, 1.0027419000210218, 1.0195604566255707, 1.0289601949473013, 1.128549823889859, 1.0047534752585967, 1.1488132735636558, 2.536720010461006, -1.0195483335512492, 1.0036380653892498, 1.0608156503543287, 2.7267964624745433, 1.0066166286097855, 1.6430734903603208, 1.0118213062280323, 1.0381116643375943, 1.0277422526437827, 1.0134840944835721, 1.6373886492189045, 1.0945046689959057, 1.0145489307766247, 1.0192875224814748, 2.125266505225048, 1.0676257433711651, 1.008208832419517, -1.004756739954964, 1.343851525491311, 1.0260581815807766, 1.099521808044459, 2.4258210470405217, 1.0007800952970591, 1.0095561420892427, -1.0081680467299516, -1.059491849967148, 1.0529823500032394, 1.0054746774081174, 2.2276476483772725, -1.5957177216530416, 1.0217983317548214, 1.1282551262442362, 0.0, 1.013710837445736, 1.0236236947439228, 1.174344492895566, 1.0812025188439973, 1.009533922247166]\n",
            "0\n",
            "[1.1038871521963498, 1.0112665425945806, 1.3314657637921765, 1.0118177983631924, 1.0014452394313422, 1.0067218369537336, 1.0386893733592122, 1.0379901570204264, 1.1318851252141873, 1.0099785276634397, 1.1563055873950276, 2.561699915607576, 1.0406387671125645, 1.0151822285089795, 1.1313308569295155, 3.4767229688690007, 1.0800886966273755, 1.4588356911802651, 1.01437174431064, 1.0161466828670385, 1.0311348331434973, 1.0124857256142776, 2.313983157303041, 1.1704160385793407, 1.020955751298699, -1.0318441560930447, 1.7600430640442788, 1.048766043746247, 1.008733420115383, -1.0175936351888262, 1.180008249766514, 1.0343106196498009, 1.0141484990482796, 2.4844379372725243, 1.0056975386127536, 1.013834155774848, 1.1042979198400544, -1.1552515999803346, 1.0566114129701931, 1.002343248004784, 2.187588397819989, -1.631354465639596, 1.003562445791248, 1.2500499624411316, 1.000271349263375, 1.004394036780256, -1.0070644854635078, 1.025492735567209, 1.0116564482236048, 1.0089516802685323]\n",
            "1\n",
            "[1.2600570703485663, 1.0740846890282438, 1.9960929365569213, 1.0097181468783025, 1.000371827468725, 1.009611283172143, 1.0347307022920558, 1.0330860809235338, 1.13795417522108, 1.0069236287810857, 1.1614722204049515, 2.402974587446598, 1.0376416395511565, 1.0343180035840815, 1.0634316928091476, 2.773379011455269, 1.0113183781718404, 1.3704353648414196, 1.0095655310116172, 1.0244852572126952, -1.1564822151552554, 1.0159768868371961, 1.736008252798623, 1.1058755196753745, 1.018336104219354, -1.2239027878419355, 1.9976301151079714, 1.06409055548691, 1.0071818881004546, -1.031521770029977, 1.2522421630645533, 1.0414017657660952, 1.0479625722475234, 2.5096137644405445, 1.0027794053870613, 1.0110995264881348, 1.0074743167726692, -1.1102559496549482, 1.0559181876896675, 1.0042757919698109, 2.168123133632702, -1.5514011980984597, 1.0396557497142869, 1.5072701234315709, 1.0046251016899206, 1.0070883274316722, -1.0383979116104756, 1.067179509109663, 1.0165578189198323, 1.0121319568564382]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlPNvS8x9OvD",
        "colab_type": "code",
        "outputId": "598ddbc5-6612-4c2e-a1b2-288832776774",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "source": [
        "\n",
        "for i in range(0,10):\n",
        "    print(test_data_images[i])\n",
        "    print(test_data_labels[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.1617874179699497, 1.0486658851908912, 1.8614041627231213, 1.0116375912431794, 1.0006039657586734, 1.0090059623089556, 1.033103103687852, 1.0354833312197067, 1.1368311872088188, 1.0088664148397761, 1.1611858598762543, 2.3227876416475746, 1.000787252572165, 1.0157710923011476, 1.0930432638576897, 3.00272660953786, 1.0218730432090986, 1.5666201285352892, 1.01393397127449, 1.015420661358545, 1.0121245660113676, 1.0127617858401097, 1.897927694930935, 1.178168580270275, 1.0160617722239533, 1.008309523002242, 1.9860843785176208, 1.0600701146264426, 1.0099980085505065, -1.0262397408044412, 1.1930792177780951, 1.0429470434042023, 1.018649203961263, 2.619966261593392, 1.0022321472735534, 1.0101181001671096, 1.0101492421814209, -1.1344773748252066, 1.0672609810726645, 1.002747229769374, 2.097552293670734, -1.4688404325362527, 1.0155266500386557, 1.2473677765681537, 0.0, 1.0038804873681613, 1.0109026731635005, 1.04984032387501, 1.098219605852044, 1.0103660288403848]\n",
            "0\n",
            "[1.2283207820929922, 1.0976865317909228, 2.1640671983644233, 1.0125817591294213, 1.0002524232686012, 1.0035478604662105, 1.0271255519051365, 1.0341526375906902, 1.1353031540511875, 1.0063537957818804, 1.147330296373803, 2.2999646686241553, 1.0286152492119855, 1.0119033737265997, 1.0704582818781485, 2.7239545367217004, 1.0092700012502298, 1.5005740062149089, 1.0117081104641972, 1.0130130151412113, -1.0077410800872384, 1.0112162667532396, 1.5238062757055602, 1.1375329203154958, 1.0197996520518064, -1.0510687437870703, 2.148263229636879, 1.0617351308914451, 1.0090103437137887, -1.0611153176310362, 1.2252774840015426, 1.0415304530990883, 1.0269255457039455, 2.663784761568172, 1.002693294876742, 1.0123502890215725, 1.0476509632061124, -1.1436816642719672, 1.0403431891431894, 1.00342838106406, 2.061761502342967, -1.6588238645585887, 1.1078256882718758, 1.2437596185999176, 0.0, 1.0063129639084964, 1.003431091288271, 1.1112083915472177, 1.1414535362244427, 1.010300126286061]\n",
            "0\n",
            "[1.171388537627366, 1.0350013165835052, 2.399492006495772, 1.0109627675610984, 1.000496457817806, 0.0, 1.0416216164448282, 1.032966258810306, 1.1240667756907965, 1.006781614730176, 1.1506416358988119, 2.1069656102692775, 1.0002945567327735, 1.0140152621026508, 1.0993079822665062, 2.9973903166233113, 1.0161722490595921, 1.1674059572322921, 1.0114156431001502, 1.0484860853455007, -1.0097037923131118, 1.015406326384087, 2.140633725134818, 1.1014686789365826, 1.0210189395013893, 1.0167610682548291, 1.1980954395508496, 1.0619219569452163, 1.0044926498278353, 1.0160423103245733, 1.273349031626, 1.0531064987694125, 1.0338753878977134, 2.5902096535653505, 1.0022745958859933, 1.014831867526764, 1.030004821005999, -1.1258071082804801, 1.0391150074199493, 1.0058983073001821, 2.1496962663578945, -1.3999193484872403, 1.068814947306454, 1.1168029334178855, 0.0, 1.0109816538643728, 1.014581100554719, 1.1268814357879158, 1.0823239116809755, 1.0110216257527203]\n",
            "1\n",
            "[1.179955738389539, 1.069333924155627, 2.19213517379921, 1.0135999009746313, 1.000174031223234, 1.0046605929575505, 1.0201674230421471, 1.035121980558728, 1.1241059389836208, 1.0055898094896625, 1.1462114742450267, 2.413098499932178, 1.00777179578388, 1.007966576578435, 1.0787865826231098, 2.86098208165483, 1.0102303960937677, 1.5999234443072448, 1.0110845824845804, 1.0328226058028176, 1.0194860521497024, 1.013790992031854, 1.7852543608872815, 1.0959444592744998, 1.0211039207914696, -1.0166759851053486, 2.1376452316498757, 1.0662796975663895, 1.0066856584229151, -1.0128627334862617, 1.2732342230423657, 1.0325125108836444, 1.0432923136367167, 2.6683113532969243, 1.0017472042776183, 1.012487160366101, 1.0172918346074207, -1.112940980619114, 1.060520687608259, 1.0053753005286892, 2.1801918461973173, -1.3150020699661344, 1.027153743698973, 1.1691357865662884, 0.0, 1.010053602790941, 1.0157370001292254, 1.116024973556115, 1.1027454213418657, 1.009131516705039]\n",
            "0\n",
            "[1.146400625006178, 1.017910312744258, 1.8220686511781379, 1.0107444144493942, 1.0009133417270515, 1.0098971568642863, 1.0582479423983433, 1.0379620232697182, 1.1221939171664186, 1.007634411492648, 1.1593135802443382, 1.583022979530808, 1.0345216543706262, 1.017489150982679, 1.13431451676295, 3.2631695728333785, 1.0417750907079206, 1.3427403891821232, 1.0098085952062767, 1.0439989074266462, 1.028535303983591, 1.0121265087599718, 2.3685230322477593, 1.1278117337702833, 1.0200838754935047, 1.0184480852590356, 0.0, 1.055141622261951, 1.0053312448920018, 1.017235030596324, 1.1782841122821899, 1.065677914673362, 1.0316151392402642, 2.6729139339556487, 1.0031371984500765, 1.0094074641788864, 1.0323269442473997, -1.1287087225146055, 1.0514269098626512, 1.0035322924819794, 2.274716528406966, 1.8918991261881115, -1.021679320306013, 1.0919534622636486, 0.0, 1.0070612807981068, -1.0200662102809466, 1.0662155669926183, 1.024202421918727, 1.0121683602120746]\n",
            "1\n",
            "[1.168341297995859, 1.0713358515637303, 2.4781002084293675, 1.0108213059045514, 0.0, 0.0, 1.050882983223125, 1.036298857867159, 1.1347828478027973, 1.0072501874766013, 1.1538194358413307, 1.3643971359322664, 1.0365399117614467, 1.0155010458113798, 1.1068844661271025, 2.916349178820342, 1.013109227109791, 1.7812899636700483, 1.0141582516147913, 1.0366433050778805, -1.0517554834875575, 1.0106928069295003, 1.8718320339811365, 1.09153190090477, 1.0162509884976494, 1.0125854295849757, 2.3233222418344357, 1.0516236211217453, 1.012150707921857, -1.0277639675726058, 1.2074498944152665, 1.021604658159071, 1.1028801202542737, 2.6644351194046068, 1.0050700365961776, 1.0092439829607542, 1.0534053864102682, -1.0606430780316745, 1.0517616515068928, 1.004449837148694, 2.0607129459859292, -1.8409919794826808, 1.0060923026516235, 1.1699831494104869, 0.0, 1.0108076231867784, -1.0159154308488205, 1.0618146171201506, 1.0611375768476425, 1.0053065769314629]\n",
            "0\n",
            "[1.106919438055763, 1.0562742858303908, 1.9763027406036349, 1.0111403764516531, 0.0, 1.008756574765, 1.0443425584750528, 1.035675875367478, 1.1340358272898623, 1.011231841036744, 1.1571133070047355, 2.2721039619101293, 1.0395947798284766, 1.0035022103160904, 1.0795628955374483, 2.8703108322032906, 1.0184403848852899, 1.3059980295498879, 1.013869827833354, 1.0189677321727098, 1.0398299701647047, 1.0131614330939562, 1.720793323939112, 1.2239105681875246, 1.0208527352320593, 1.057392206676608, 1.2219181443300746, 1.0502157530279752, 1.0085049997495978, -1.035743037665959, 1.1455391676069817, 1.0462996292757314, 1.0337041066200578, 2.5873730489930464, 1.00515068591981, 1.0155735383188291, 1.0872783526368774, -1.125598037804976, 1.045925486598985, 1.002255111083872, 2.0626271033889645, -1.7027656066651342, 1.027855744950571, 1.232130468897938, 0.0, 1.0027643535708055, 1.0033404468717435, 1.0238082477761175, 1.0036115352076285, 1.0107125100315024]\n",
            "0\n",
            "[1.21090895145114, 1.1383409143991994, 1.5190899848994093, 1.0099406244357805, 0.0, 1.0067586966124875, 1.0491288280375284, 1.0309628717963575, 1.143077908967418, 1.0155059907715778, 1.1675252736098234, 2.2441731746411797, 1.0140705547209028, 1.0398139222950489, 1.0816864004327464, 2.6579398037539246, 1.0042842378667922, 1.6613724909912782, 1.0111923117379058, 1.0103037736643827, -1.2827806682491263, 1.0165896730343147, 1.5912438557010138, 1.0749001475914866, 1.0156114558797555, -1.4075115722778013, 1.9297723486716096, 1.0554532560018053, 1.0065971665496412, -1.1030805489216613, 1.2639892773221146, 1.0164925566722987, 1.1322488000048592, 2.6990863796635716, 1.0002606053197562, 1.0171194797473602, 1.0703260685733291, -1.0361527866412685, 1.0344494888245042, 1.0065939584340182, 2.0451351351496876, -1.8340606559738644, 1.2398265703632476, 1.6031703645295736, 1.0083740242940211, 1.0133285427407117, -1.1217918654924726, 1.1200383001850467, 1.006432238703096, 1.002396634675756]\n",
            "0\n",
            "[1.192521178160099, 1.0424896687826006, 2.177175640347901, 1.0176267478909335, 0.0, 1.005524507403475, 1.0210653626953379, 1.0342572429128594, 1.120323152455009, 1.0042145758090943, 1.1518957727683292, 1.691751433822883, 1.017038559153011, 1.0094869296971765, 1.0743866859829352, 2.7461646269410602, 1.0073664724562963, 1.5754476508669542, 1.009369511076468, 1.0299090779568978, 1.0226920435695923, 1.0130838592248441, 1.7765312094113406, 1.1187394451221095, 1.0205114363823957, -1.0318640929703269, 2.2340260201617648, 1.060304153404018, 1.0078870029502442, -1.0552632433815485, 1.2874057594482144, 1.0369526194529746, 1.044401767661692, 2.6845814745100807, 1.0081160042540844, 1.0142718612850414, 1.0271324062288922, -1.113513187803172, 1.0471318967012933, 1.0057692860432366, 2.122019172080031, -1.7330712131117096, 1.1032897868201472, 1.187255551060186, 0.0, 1.0104601580022008, 1.0173649885631746, 1.1384195471424363, 1.0485587132507017, 1.007876511448403]\n",
            "0\n",
            "[1.1545399115255233, 1.0244775810442073, 2.6106080020418787, 1.009718019473006, 1.0004234954898465, 0.0, 1.0505854463372648, 1.0357892732118654, 1.1213726928672878, 1.0083672508304717, 1.1485415778500017, -1.0135695526410464, 1.0272567036760414, 1.0114101014036827, 1.1043371992171487, 3.1368853775816543, 1.0321063295791413, 1.2656148712428736, 1.0104137319788737, 1.0527358691291588, 1.0212931450766614, 1.0140695456411253, 2.1934168136174037, 1.1516309001433438, 1.0210754576349994, 1.0108334208923482, 1.1203939249053005, 1.0613254142852275, 1.0048194946768954, 1.0149942660990947, 1.2250796653814755, 1.0676145931008065, 1.0235748704751824, 2.5910234027749066, 1.003861599632908, 1.0159325539974684, 1.0255716049465604, -1.1347411326713368, 1.0453534957050743, 1.0039934049422465, 2.1855279897674706, -1.2028646877874347, 1.055776124980368, 1.0948259660999966, 0.0, 1.0077701747319685, 1.0139975165155228, 1.105542542761186, 1.083261039053805, 1.0112545666385675]\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7tz2IzL9w4q",
        "colab_type": "code",
        "outputId": "07c6f643-2079-41b0-8a2f-ed7b600ea5bf",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "\n",
        "df_train=pd.DataFrame(train_data_images)\n",
        "df_train.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>108059</th>\n",
              "      <td>1.147890</td>\n",
              "      <td>1.043750</td>\n",
              "      <td>1.334224</td>\n",
              "      <td>1.008745</td>\n",
              "      <td>1.000073</td>\n",
              "      <td>1.019896</td>\n",
              "      <td>1.046833</td>\n",
              "      <td>1.036275</td>\n",
              "      <td>1.115281</td>\n",
              "      <td>1.010999</td>\n",
              "      <td>1.150241</td>\n",
              "      <td>2.281981</td>\n",
              "      <td>1.020134</td>\n",
              "      <td>1.005067</td>\n",
              "      <td>1.092659</td>\n",
              "      <td>3.007906</td>\n",
              "      <td>1.024179</td>\n",
              "      <td>1.296185</td>\n",
              "      <td>1.011061</td>\n",
              "      <td>1.044712</td>\n",
              "      <td>1.021903</td>\n",
              "      <td>1.013959</td>\n",
              "      <td>1.991142</td>\n",
              "      <td>1.195617</td>\n",
              "      <td>1.020952</td>\n",
              "      <td>-1.000850</td>\n",
              "      <td>1.157872</td>\n",
              "      <td>1.055609</td>\n",
              "      <td>1.007709</td>\n",
              "      <td>1.003600</td>\n",
              "      <td>1.193883</td>\n",
              "      <td>1.057977</td>\n",
              "      <td>1.021949</td>\n",
              "      <td>2.577677</td>\n",
              "      <td>1.005208</td>\n",
              "      <td>1.016012</td>\n",
              "      <td>1.034310</td>\n",
              "      <td>-1.116446</td>\n",
              "      <td>1.052208</td>\n",
              "      <td>1.003543</td>\n",
              "      <td>2.144400</td>\n",
              "      <td>-1.258178</td>\n",
              "      <td>1.027156</td>\n",
              "      <td>1.163405</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.004672</td>\n",
              "      <td>1.009158</td>\n",
              "      <td>1.044947</td>\n",
              "      <td>1.048584</td>\n",
              "      <td>1.009049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108060</th>\n",
              "      <td>1.145936</td>\n",
              "      <td>1.058379</td>\n",
              "      <td>2.153357</td>\n",
              "      <td>1.015132</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.005538</td>\n",
              "      <td>1.038111</td>\n",
              "      <td>1.035012</td>\n",
              "      <td>1.132662</td>\n",
              "      <td>1.006144</td>\n",
              "      <td>1.156795</td>\n",
              "      <td>2.331190</td>\n",
              "      <td>1.021490</td>\n",
              "      <td>1.003308</td>\n",
              "      <td>1.078810</td>\n",
              "      <td>2.910547</td>\n",
              "      <td>1.017064</td>\n",
              "      <td>1.442243</td>\n",
              "      <td>1.014213</td>\n",
              "      <td>1.034828</td>\n",
              "      <td>1.043745</td>\n",
              "      <td>1.013374</td>\n",
              "      <td>1.646775</td>\n",
              "      <td>1.170409</td>\n",
              "      <td>1.017389</td>\n",
              "      <td>1.036404</td>\n",
              "      <td>1.953903</td>\n",
              "      <td>1.062539</td>\n",
              "      <td>1.009600</td>\n",
              "      <td>-1.004748</td>\n",
              "      <td>1.218597</td>\n",
              "      <td>1.033726</td>\n",
              "      <td>1.050461</td>\n",
              "      <td>2.523982</td>\n",
              "      <td>1.004207</td>\n",
              "      <td>1.011526</td>\n",
              "      <td>-1.029025</td>\n",
              "      <td>-1.094474</td>\n",
              "      <td>1.068136</td>\n",
              "      <td>1.002350</td>\n",
              "      <td>2.185015</td>\n",
              "      <td>-1.424220</td>\n",
              "      <td>-1.034224</td>\n",
              "      <td>1.185110</td>\n",
              "      <td>1.000087</td>\n",
              "      <td>1.004425</td>\n",
              "      <td>1.012963</td>\n",
              "      <td>1.086731</td>\n",
              "      <td>1.067746</td>\n",
              "      <td>1.008406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108061</th>\n",
              "      <td>1.211452</td>\n",
              "      <td>1.071455</td>\n",
              "      <td>2.002154</td>\n",
              "      <td>1.010652</td>\n",
              "      <td>1.000302</td>\n",
              "      <td>1.004363</td>\n",
              "      <td>1.040636</td>\n",
              "      <td>1.034342</td>\n",
              "      <td>1.133740</td>\n",
              "      <td>1.009471</td>\n",
              "      <td>1.160864</td>\n",
              "      <td>2.160198</td>\n",
              "      <td>1.000944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.101821</td>\n",
              "      <td>2.794473</td>\n",
              "      <td>1.014844</td>\n",
              "      <td>1.742111</td>\n",
              "      <td>1.015150</td>\n",
              "      <td>1.037299</td>\n",
              "      <td>1.028366</td>\n",
              "      <td>1.011632</td>\n",
              "      <td>1.361371</td>\n",
              "      <td>1.425585</td>\n",
              "      <td>1.019329</td>\n",
              "      <td>1.018963</td>\n",
              "      <td>2.187673</td>\n",
              "      <td>1.072746</td>\n",
              "      <td>1.006682</td>\n",
              "      <td>1.038427</td>\n",
              "      <td>1.229365</td>\n",
              "      <td>1.004695</td>\n",
              "      <td>1.028167</td>\n",
              "      <td>2.589213</td>\n",
              "      <td>1.004270</td>\n",
              "      <td>1.017015</td>\n",
              "      <td>1.011546</td>\n",
              "      <td>-1.129906</td>\n",
              "      <td>1.056580</td>\n",
              "      <td>1.001317</td>\n",
              "      <td>2.227210</td>\n",
              "      <td>1.509397</td>\n",
              "      <td>1.010389</td>\n",
              "      <td>1.069188</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000482</td>\n",
              "      <td>1.004791</td>\n",
              "      <td>1.129125</td>\n",
              "      <td>1.223648</td>\n",
              "      <td>1.009274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108062</th>\n",
              "      <td>1.134922</td>\n",
              "      <td>1.066159</td>\n",
              "      <td>2.043366</td>\n",
              "      <td>1.011211</td>\n",
              "      <td>1.000213</td>\n",
              "      <td>1.004517</td>\n",
              "      <td>1.044639</td>\n",
              "      <td>1.035402</td>\n",
              "      <td>1.128433</td>\n",
              "      <td>1.010397</td>\n",
              "      <td>1.154180</td>\n",
              "      <td>2.375638</td>\n",
              "      <td>1.035445</td>\n",
              "      <td>1.007804</td>\n",
              "      <td>1.102373</td>\n",
              "      <td>2.964624</td>\n",
              "      <td>1.015308</td>\n",
              "      <td>1.515124</td>\n",
              "      <td>1.012279</td>\n",
              "      <td>1.039941</td>\n",
              "      <td>1.016812</td>\n",
              "      <td>1.012796</td>\n",
              "      <td>1.920135</td>\n",
              "      <td>1.133606</td>\n",
              "      <td>1.019733</td>\n",
              "      <td>-1.015280</td>\n",
              "      <td>2.218475</td>\n",
              "      <td>1.053303</td>\n",
              "      <td>1.009785</td>\n",
              "      <td>-1.046634</td>\n",
              "      <td>1.192573</td>\n",
              "      <td>1.030245</td>\n",
              "      <td>1.053233</td>\n",
              "      <td>2.678069</td>\n",
              "      <td>1.003322</td>\n",
              "      <td>1.012693</td>\n",
              "      <td>1.025014</td>\n",
              "      <td>-1.087927</td>\n",
              "      <td>1.049416</td>\n",
              "      <td>1.003593</td>\n",
              "      <td>2.051291</td>\n",
              "      <td>-1.725151</td>\n",
              "      <td>1.098996</td>\n",
              "      <td>1.182625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.007822</td>\n",
              "      <td>1.004382</td>\n",
              "      <td>1.046740</td>\n",
              "      <td>-1.000180</td>\n",
              "      <td>1.007586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108063</th>\n",
              "      <td>1.138470</td>\n",
              "      <td>1.090076</td>\n",
              "      <td>2.109899</td>\n",
              "      <td>1.010417</td>\n",
              "      <td>1.000404</td>\n",
              "      <td>1.002608</td>\n",
              "      <td>1.070533</td>\n",
              "      <td>1.034272</td>\n",
              "      <td>1.141978</td>\n",
              "      <td>1.007396</td>\n",
              "      <td>1.159092</td>\n",
              "      <td>2.067134</td>\n",
              "      <td>-1.004143</td>\n",
              "      <td>1.026481</td>\n",
              "      <td>1.082007</td>\n",
              "      <td>2.793111</td>\n",
              "      <td>1.011356</td>\n",
              "      <td>1.470238</td>\n",
              "      <td>1.012628</td>\n",
              "      <td>1.043154</td>\n",
              "      <td>-1.066192</td>\n",
              "      <td>1.012103</td>\n",
              "      <td>1.796821</td>\n",
              "      <td>1.091609</td>\n",
              "      <td>1.021109</td>\n",
              "      <td>-1.069875</td>\n",
              "      <td>2.055355</td>\n",
              "      <td>1.046554</td>\n",
              "      <td>1.006650</td>\n",
              "      <td>-1.071927</td>\n",
              "      <td>1.214549</td>\n",
              "      <td>1.035871</td>\n",
              "      <td>1.123713</td>\n",
              "      <td>2.695424</td>\n",
              "      <td>1.007333</td>\n",
              "      <td>1.014481</td>\n",
              "      <td>1.118395</td>\n",
              "      <td>-1.034930</td>\n",
              "      <td>1.034083</td>\n",
              "      <td>1.004631</td>\n",
              "      <td>2.008475</td>\n",
              "      <td>-1.771126</td>\n",
              "      <td>1.148279</td>\n",
              "      <td>1.284813</td>\n",
              "      <td>1.000270</td>\n",
              "      <td>1.010381</td>\n",
              "      <td>-1.016545</td>\n",
              "      <td>1.034692</td>\n",
              "      <td>1.001704</td>\n",
              "      <td>1.007498</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2   ...        47        48        49\n",
              "108059  1.147890  1.043750  1.334224  ...  1.044947  1.048584  1.009049\n",
              "108060  1.145936  1.058379  2.153357  ...  1.086731  1.067746  1.008406\n",
              "108061  1.211452  1.071455  2.002154  ...  1.129125  1.223648  1.009274\n",
              "108062  1.134922  1.066159  2.043366  ...  1.046740 -1.000180  1.007586\n",
              "108063  1.138470  1.090076  2.109899  ...  1.034692  1.001704  1.007498\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vgvhav1AiZr",
        "colab_type": "code",
        "outputId": "6b22f408-a988-46b5-cd0c-4a5135c31818",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "\n",
        "df_test=pd.DataFrame(test_data_images)\n",
        "df_test.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>41</th>\n",
              "      <th>42</th>\n",
              "      <th>43</th>\n",
              "      <th>44</th>\n",
              "      <th>45</th>\n",
              "      <th>46</th>\n",
              "      <th>47</th>\n",
              "      <th>48</th>\n",
              "      <th>49</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21995</th>\n",
              "      <td>1.197069</td>\n",
              "      <td>1.056649</td>\n",
              "      <td>2.065916</td>\n",
              "      <td>1.010860</td>\n",
              "      <td>1.000550</td>\n",
              "      <td>1.005844</td>\n",
              "      <td>1.030231</td>\n",
              "      <td>1.032142</td>\n",
              "      <td>1.137374</td>\n",
              "      <td>1.005393</td>\n",
              "      <td>1.168051</td>\n",
              "      <td>2.671152</td>\n",
              "      <td>1.037563</td>\n",
              "      <td>1.023984</td>\n",
              "      <td>1.061687</td>\n",
              "      <td>2.830560</td>\n",
              "      <td>1.014153</td>\n",
              "      <td>1.276567</td>\n",
              "      <td>1.011031</td>\n",
              "      <td>1.051659</td>\n",
              "      <td>-1.088219</td>\n",
              "      <td>1.014849</td>\n",
              "      <td>1.780820</td>\n",
              "      <td>1.150341</td>\n",
              "      <td>1.018643</td>\n",
              "      <td>-1.111704</td>\n",
              "      <td>1.140389</td>\n",
              "      <td>1.059926</td>\n",
              "      <td>1.007331</td>\n",
              "      <td>-1.022618</td>\n",
              "      <td>1.254357</td>\n",
              "      <td>1.048509</td>\n",
              "      <td>1.041831</td>\n",
              "      <td>2.356039</td>\n",
              "      <td>1.004007</td>\n",
              "      <td>1.016539</td>\n",
              "      <td>1.009089</td>\n",
              "      <td>-1.109141</td>\n",
              "      <td>1.045850</td>\n",
              "      <td>1.003199</td>\n",
              "      <td>2.137933</td>\n",
              "      <td>-1.577863</td>\n",
              "      <td>1.044390</td>\n",
              "      <td>1.381097</td>\n",
              "      <td>1.001806</td>\n",
              "      <td>1.006789</td>\n",
              "      <td>-1.010567</td>\n",
              "      <td>1.053781</td>\n",
              "      <td>1.066255</td>\n",
              "      <td>1.008449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21996</th>\n",
              "      <td>1.224671</td>\n",
              "      <td>1.068671</td>\n",
              "      <td>1.957673</td>\n",
              "      <td>1.010053</td>\n",
              "      <td>1.000113</td>\n",
              "      <td>1.003311</td>\n",
              "      <td>1.032379</td>\n",
              "      <td>1.033627</td>\n",
              "      <td>1.128662</td>\n",
              "      <td>1.010402</td>\n",
              "      <td>1.150965</td>\n",
              "      <td>2.148883</td>\n",
              "      <td>1.013416</td>\n",
              "      <td>1.026180</td>\n",
              "      <td>1.111224</td>\n",
              "      <td>2.833360</td>\n",
              "      <td>1.009578</td>\n",
              "      <td>1.447273</td>\n",
              "      <td>1.010172</td>\n",
              "      <td>1.020361</td>\n",
              "      <td>-1.044673</td>\n",
              "      <td>1.008511</td>\n",
              "      <td>1.603792</td>\n",
              "      <td>1.174938</td>\n",
              "      <td>1.014488</td>\n",
              "      <td>-1.061268</td>\n",
              "      <td>2.154844</td>\n",
              "      <td>1.069998</td>\n",
              "      <td>1.006112</td>\n",
              "      <td>1.028845</td>\n",
              "      <td>1.232363</td>\n",
              "      <td>1.041324</td>\n",
              "      <td>1.097075</td>\n",
              "      <td>2.666639</td>\n",
              "      <td>1.000787</td>\n",
              "      <td>1.017621</td>\n",
              "      <td>-1.017455</td>\n",
              "      <td>-1.052206</td>\n",
              "      <td>1.047754</td>\n",
              "      <td>1.002459</td>\n",
              "      <td>2.251185</td>\n",
              "      <td>1.157201</td>\n",
              "      <td>1.053241</td>\n",
              "      <td>1.169413</td>\n",
              "      <td>1.000226</td>\n",
              "      <td>1.005403</td>\n",
              "      <td>-1.022807</td>\n",
              "      <td>1.145944</td>\n",
              "      <td>1.111114</td>\n",
              "      <td>1.007724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21997</th>\n",
              "      <td>1.178787</td>\n",
              "      <td>1.069832</td>\n",
              "      <td>2.319383</td>\n",
              "      <td>1.013666</td>\n",
              "      <td>1.000104</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.021055</td>\n",
              "      <td>1.032424</td>\n",
              "      <td>1.121889</td>\n",
              "      <td>1.005166</td>\n",
              "      <td>1.153134</td>\n",
              "      <td>-1.018266</td>\n",
              "      <td>1.031118</td>\n",
              "      <td>1.019362</td>\n",
              "      <td>1.071815</td>\n",
              "      <td>2.669074</td>\n",
              "      <td>1.007363</td>\n",
              "      <td>1.184788</td>\n",
              "      <td>1.009331</td>\n",
              "      <td>1.017464</td>\n",
              "      <td>-1.029847</td>\n",
              "      <td>1.010446</td>\n",
              "      <td>1.754789</td>\n",
              "      <td>1.098967</td>\n",
              "      <td>1.019981</td>\n",
              "      <td>-1.007351</td>\n",
              "      <td>2.131336</td>\n",
              "      <td>1.073344</td>\n",
              "      <td>1.006808</td>\n",
              "      <td>1.015349</td>\n",
              "      <td>1.257618</td>\n",
              "      <td>1.041692</td>\n",
              "      <td>1.033752</td>\n",
              "      <td>2.610310</td>\n",
              "      <td>1.000978</td>\n",
              "      <td>1.009133</td>\n",
              "      <td>-1.019850</td>\n",
              "      <td>-1.100735</td>\n",
              "      <td>1.079151</td>\n",
              "      <td>1.004378</td>\n",
              "      <td>2.295486</td>\n",
              "      <td>-1.370232</td>\n",
              "      <td>-1.026333</td>\n",
              "      <td>1.137017</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.012442</td>\n",
              "      <td>-1.025309</td>\n",
              "      <td>1.194630</td>\n",
              "      <td>1.088393</td>\n",
              "      <td>1.010370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21998</th>\n",
              "      <td>1.120479</td>\n",
              "      <td>1.055495</td>\n",
              "      <td>2.249421</td>\n",
              "      <td>1.010541</td>\n",
              "      <td>1.000117</td>\n",
              "      <td>1.005695</td>\n",
              "      <td>1.074395</td>\n",
              "      <td>1.037474</td>\n",
              "      <td>1.134895</td>\n",
              "      <td>1.010855</td>\n",
              "      <td>1.157458</td>\n",
              "      <td>1.467342</td>\n",
              "      <td>1.040510</td>\n",
              "      <td>1.001297</td>\n",
              "      <td>1.072678</td>\n",
              "      <td>2.763559</td>\n",
              "      <td>1.020763</td>\n",
              "      <td>1.392180</td>\n",
              "      <td>1.015974</td>\n",
              "      <td>1.046070</td>\n",
              "      <td>1.058372</td>\n",
              "      <td>1.013598</td>\n",
              "      <td>1.750545</td>\n",
              "      <td>1.210941</td>\n",
              "      <td>1.020898</td>\n",
              "      <td>1.062501</td>\n",
              "      <td>1.228645</td>\n",
              "      <td>1.054787</td>\n",
              "      <td>1.006410</td>\n",
              "      <td>-1.047816</td>\n",
              "      <td>1.141639</td>\n",
              "      <td>1.047168</td>\n",
              "      <td>1.027019</td>\n",
              "      <td>2.623792</td>\n",
              "      <td>1.004467</td>\n",
              "      <td>1.014113</td>\n",
              "      <td>1.059051</td>\n",
              "      <td>-1.138714</td>\n",
              "      <td>1.033466</td>\n",
              "      <td>1.001917</td>\n",
              "      <td>1.994397</td>\n",
              "      <td>-1.480549</td>\n",
              "      <td>1.094372</td>\n",
              "      <td>1.174085</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.002484</td>\n",
              "      <td>1.005661</td>\n",
              "      <td>1.018166</td>\n",
              "      <td>-1.015457</td>\n",
              "      <td>1.014090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21999</th>\n",
              "      <td>1.115214</td>\n",
              "      <td>1.025275</td>\n",
              "      <td>1.597404</td>\n",
              "      <td>1.010190</td>\n",
              "      <td>1.000861</td>\n",
              "      <td>1.019707</td>\n",
              "      <td>1.057601</td>\n",
              "      <td>1.036572</td>\n",
              "      <td>1.128303</td>\n",
              "      <td>1.010627</td>\n",
              "      <td>1.157197</td>\n",
              "      <td>2.509762</td>\n",
              "      <td>1.032239</td>\n",
              "      <td>1.014066</td>\n",
              "      <td>1.095668</td>\n",
              "      <td>3.181318</td>\n",
              "      <td>1.041473</td>\n",
              "      <td>1.248901</td>\n",
              "      <td>1.014074</td>\n",
              "      <td>1.047320</td>\n",
              "      <td>1.040452</td>\n",
              "      <td>1.013573</td>\n",
              "      <td>2.088529</td>\n",
              "      <td>1.206058</td>\n",
              "      <td>1.020766</td>\n",
              "      <td>1.002792</td>\n",
              "      <td>1.720584</td>\n",
              "      <td>1.050105</td>\n",
              "      <td>1.005779</td>\n",
              "      <td>-1.004738</td>\n",
              "      <td>1.179131</td>\n",
              "      <td>1.048245</td>\n",
              "      <td>1.020725</td>\n",
              "      <td>2.442495</td>\n",
              "      <td>1.005129</td>\n",
              "      <td>1.016351</td>\n",
              "      <td>1.043085</td>\n",
              "      <td>-1.159808</td>\n",
              "      <td>1.051885</td>\n",
              "      <td>1.002568</td>\n",
              "      <td>2.191297</td>\n",
              "      <td>-1.172581</td>\n",
              "      <td>1.006011</td>\n",
              "      <td>1.200042</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.004257</td>\n",
              "      <td>-1.001632</td>\n",
              "      <td>1.039989</td>\n",
              "      <td>1.006659</td>\n",
              "      <td>1.008643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0         1         2   ...        47        48        49\n",
              "21995  1.197069  1.056649  2.065916  ...  1.053781  1.066255  1.008449\n",
              "21996  1.224671  1.068671  1.957673  ...  1.145944  1.111114  1.007724\n",
              "21997  1.178787  1.069832  2.319383  ...  1.194630  1.088393  1.010370\n",
              "21998  1.120479  1.055495  2.249421  ...  1.018166 -1.015457  1.014090\n",
              "21999  1.115214  1.025275  1.597404  ...  1.039989  1.006659  1.008643\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xtl_FHR3__UL",
        "colab_type": "code",
        "outputId": "0287182b-1281-45dc-d8ad-cb3f22146e16",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "\n",
        "df1_train = df_train.iloc[:, :]\n",
        "df1_train.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "5     0\n",
              "6     0\n",
              "7     0\n",
              "8     0\n",
              "9     0\n",
              "10    0\n",
              "11    0\n",
              "12    0\n",
              "13    0\n",
              "14    0\n",
              "15    0\n",
              "16    0\n",
              "17    0\n",
              "18    0\n",
              "19    0\n",
              "20    0\n",
              "21    0\n",
              "22    0\n",
              "23    0\n",
              "24    0\n",
              "25    0\n",
              "26    0\n",
              "27    0\n",
              "28    0\n",
              "29    0\n",
              "30    0\n",
              "31    0\n",
              "32    0\n",
              "33    0\n",
              "34    0\n",
              "35    0\n",
              "36    0\n",
              "37    0\n",
              "38    0\n",
              "39    0\n",
              "40    0\n",
              "41    0\n",
              "42    0\n",
              "43    0\n",
              "44    0\n",
              "45    0\n",
              "46    0\n",
              "47    0\n",
              "48    0\n",
              "49    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRt-0mgKAnHC",
        "colab_type": "code",
        "outputId": "2e315230-ea0e-41e3-b8c3-6bd1537eeacb",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "\n",
        "df1_test = df_test.iloc[:, :]\n",
        "df1_test.isnull().sum()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     0\n",
              "1     0\n",
              "2     0\n",
              "3     0\n",
              "4     0\n",
              "5     0\n",
              "6     0\n",
              "7     0\n",
              "8     0\n",
              "9     0\n",
              "10    0\n",
              "11    0\n",
              "12    0\n",
              "13    0\n",
              "14    0\n",
              "15    0\n",
              "16    0\n",
              "17    0\n",
              "18    0\n",
              "19    0\n",
              "20    0\n",
              "21    0\n",
              "22    0\n",
              "23    0\n",
              "24    0\n",
              "25    0\n",
              "26    0\n",
              "27    0\n",
              "28    0\n",
              "29    0\n",
              "30    0\n",
              "31    0\n",
              "32    0\n",
              "33    0\n",
              "34    0\n",
              "35    0\n",
              "36    0\n",
              "37    0\n",
              "38    0\n",
              "39    0\n",
              "40    0\n",
              "41    0\n",
              "42    0\n",
              "43    0\n",
              "44    0\n",
              "45    0\n",
              "46    0\n",
              "47    0\n",
              "48    0\n",
              "49    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phuQnG7NA1nI",
        "colab_type": "code",
        "outputId": "9d2fa7b1-9fd3-4ed7-e769-353686e1279f",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "df2_train = pd.get_dummies(df1_train)\n",
        "df2_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108064, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCtS3uH5A82C",
        "colab_type": "code",
        "outputId": "7e41e1a3-b39b-4165-d255-ecbbad42f278",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "df2_test = pd.get_dummies(df1_test)\n",
        "df2_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7guJpMpwBA-Y",
        "colab_type": "code",
        "outputId": "5fa64117-b94f-484b-cd74-237958e2d4f1",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "\n",
        "cols_train = df2_train.columns.tolist()\n",
        "cols_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2tYh1JUBKu4",
        "colab_type": "code",
        "outputId": "e0520f9a-6f6a-4cf1-96aa-8e1690499045",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "\n",
        "cols_test = df2_test.columns.tolist()\n",
        "cols_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 4,\n",
              " 5,\n",
              " 6,\n",
              " 7,\n",
              " 8,\n",
              " 9,\n",
              " 10,\n",
              " 11,\n",
              " 12,\n",
              " 13,\n",
              " 14,\n",
              " 15,\n",
              " 16,\n",
              " 17,\n",
              " 18,\n",
              " 19,\n",
              " 20,\n",
              " 21,\n",
              " 22,\n",
              " 23,\n",
              " 24,\n",
              " 25,\n",
              " 26,\n",
              " 27,\n",
              " 28,\n",
              " 29,\n",
              " 30,\n",
              " 31,\n",
              " 32,\n",
              " 33,\n",
              " 34,\n",
              " 35,\n",
              " 36,\n",
              " 37,\n",
              " 38,\n",
              " 39,\n",
              " 40,\n",
              " 41,\n",
              " 42,\n",
              " 43,\n",
              " 44,\n",
              " 45,\n",
              " 46,\n",
              " 47,\n",
              " 48,\n",
              " 49]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cxWpahSBOt3",
        "colab_type": "code",
        "outputId": "9dbf53fb-6edc-4c9d-ef43-0a2279a510f6",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "x_train = df2_train\n",
        "x_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108064, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri4HC4-tBh5e",
        "colab_type": "code",
        "outputId": "ef81797a-d81e-4aa2-8d82-3687e821c5f7",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "x_test = df2_test\n",
        "x_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5y8KvUDBqjY",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "sc.fit(x_train)\n",
        "x_train_std = sc.transform(x_train)\n",
        "x_test_std = sc.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti-eFJ7tCLLV",
        "colab_type": "code",
        "outputId": "9f229ab7-87f2-4039-f97e-3c968de69d6a",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "y_train = pd.DataFrame(train_data_labels)\n",
        "y_train.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>108059</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108060</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108061</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108062</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108063</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0\n",
              "108059  1\n",
              "108060  0\n",
              "108061  0\n",
              "108062  0\n",
              "108063  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHHPuQkgDLcC",
        "colab_type": "code",
        "outputId": "74f71bb9-aefd-439e-a69e-8d08b60d3af2",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "y_test = pd.DataFrame(test_data_labels)\n",
        "y_test.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21995</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21996</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21997</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21998</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21999</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0\n",
              "21995  0\n",
              "21996  0\n",
              "21997  0\n",
              "21998  0\n",
              "21999  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpEFzFWODQtx",
        "colab_type": "code",
        "outputId": "be1878b9-fe26-43c5-bfc9-223921e4063b",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "\n",
        "y2_train = y_train\n",
        "y2_train.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>108064.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.280056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.449029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   0\n",
              "count  108064.000000\n",
              "mean        0.280056\n",
              "std         0.449029\n",
              "min         0.000000\n",
              "25%         0.000000\n",
              "50%         0.000000\n",
              "75%         1.000000\n",
              "max         1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilxSJX0fDhWx",
        "colab_type": "code",
        "outputId": "d841f840-f339-4eba-9eee-3610c18af3bd",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "\n",
        "y2_test = y_test\n",
        "y2_test.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>22000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.283409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.450664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0\n",
              "count  22000.000000\n",
              "mean       0.283409\n",
              "std        0.450664\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        1.000000\n",
              "max        1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REoMAD4gDmzf",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ir5ZoBtDtI9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import Activation\n",
        "from keras.utils.generic_utils import get_custom_objects\n",
        "def swish(x):\n",
        "    return (K.sigmoid(x) * x)\n",
        "get_custom_objects().update({'swish': swish })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YavaR3QUD0-x",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.layers.normalization import BatchNormalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKqpcPjmD2-N",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "earlyStopping=EarlyStopping(monitor= 'val_loss', patience= 4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn7AnJfGD5bh",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', \n",
        "                                            patience=2, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQ1jQqIHD8Np",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdpmyH34D-QC",
        "colab_type": "code",
        "outputId": "482b93ec-5c17-4d40-f469-9673cddfd4f7",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=500, input_dim=50, kernel_initializer='glorot_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "for i in range(9):\n",
        "    model.add(Dense(units=500, kernel_initializer='glorot_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('sigmoid'))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=100, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "min_epochs = 1\n",
        "min_val_loss = 1000\n",
        "for i in range(0,len(acc)):\n",
        "    if val_loss[i]<min_val_loss:\n",
        "      min_val_loss = val_loss[i]\n",
        "      min_epochs = i+1\n",
        "      \n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=min_epochs, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "scores = model.evaluate(x_test, y2_test, verbose=1)\n",
        "scores[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 86451 samples, validate on 21613 samples\n",
            "Epoch 1/100\n",
            "86451/86451 [==============================] - 88s 1ms/step - loss: 0.1025 - acc: 0.8729 - val_loss: 0.0819 - val_acc: 0.8921\n",
            "Epoch 2/100\n",
            "86451/86451 [==============================] - 81s 934us/step - loss: 0.0859 - acc: 0.8932 - val_loss: 0.0953 - val_acc: 0.8865\n",
            "Epoch 3/100\n",
            "86451/86451 [==============================] - 81s 937us/step - loss: 0.0798 - acc: 0.9011 - val_loss: 0.0923 - val_acc: 0.9098\n",
            "\n",
            "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 4/100\n",
            "86451/86451 [==============================] - 81s 933us/step - loss: 0.0719 - acc: 0.9076 - val_loss: 0.0867 - val_acc: 0.9101\n",
            "Epoch 5/100\n",
            "86451/86451 [==============================] - 81s 939us/step - loss: 0.0701 - acc: 0.9114 - val_loss: 0.0777 - val_acc: 0.8970\n",
            "Epoch 6/100\n",
            "86451/86451 [==============================] - 81s 936us/step - loss: 0.0691 - acc: 0.9126 - val_loss: 0.0837 - val_acc: 0.9071\n",
            "Epoch 7/100\n",
            "86451/86451 [==============================] - 81s 935us/step - loss: 0.0679 - acc: 0.9140 - val_loss: 0.0913 - val_acc: 0.8833\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 8/100\n",
            "86451/86451 [==============================] - 81s 936us/step - loss: 0.0649 - acc: 0.9164 - val_loss: 0.0851 - val_acc: 0.8904\n",
            "Epoch 9/100\n",
            "86451/86451 [==============================] - 81s 938us/step - loss: 0.0640 - acc: 0.9179 - val_loss: 0.0673 - val_acc: 0.9166\n",
            "Epoch 10/100\n",
            "86451/86451 [==============================] - 81s 937us/step - loss: 0.0624 - acc: 0.9188 - val_loss: 0.0725 - val_acc: 0.9057\n",
            "Epoch 11/100\n",
            "86451/86451 [==============================] - 81s 933us/step - loss: 0.0621 - acc: 0.9196 - val_loss: 0.0614 - val_acc: 0.9220\n",
            "Epoch 12/100\n",
            "86451/86451 [==============================] - 84s 971us/step - loss: 0.0622 - acc: 0.9208 - val_loss: 0.0668 - val_acc: 0.9125\n",
            "Epoch 13/100\n",
            " 6880/86451 [=>............................] - ETA: 1:13 - loss: 0.0627 - acc: 0.9195"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZPiJCChxya1",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "y2_test_pred = model.predict(x_test,batch_size=32,verbose=0) #y2_test #ture\n",
        "y2_test_pred_ = []\n",
        "for i in range(0,len(y2_test_pred)):\n",
        "    if y2_test_pred[i]>=0.5:\n",
        "        y2_test_pred_.append(1)\n",
        "    else:\n",
        "        y2_test_pred_.append(0)\n",
        "metrics.precision_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGVyaYx40_op",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.recall_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLQvtP-x1H6h",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.f1_score(test_data_labels, y2_test_pred_) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROANdFJ91Osg",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H-icBAVuNKk",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLLKQvqluNaO",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4cgG-LFEeHT",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xG4vg8C7pKPE",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opeACePCGsNA",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=500, input_dim=50, kernel_initializer='glorot_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('sigmoid'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "for i in range(9):\n",
        "    model.add(Dense(units=500, kernel_initializer='glorot_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('sigmoid'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=100, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "min_epochs = 1\n",
        "min_val_loss = 1000\n",
        "for i in range(0,len(acc)):\n",
        "    if val_loss[i]<min_val_loss:\n",
        "      min_val_loss = val_loss[i]\n",
        "      min_epochs = i+1\n",
        "      \n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=min_epochs, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "scores = model.evaluate(x_test, y2_test, verbose=1)\n",
        "scores[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DCa3dtSs3pIr",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "y2_test_pred = model.predict(x_test,batch_size=32,verbose=0) #y2_test #ture\n",
        "y2_test_pred_ = []\n",
        "for i in range(0,len(y2_test_pred)):\n",
        "    if y2_test_pred[i]>=0.5:\n",
        "        y2_test_pred_.append(1)\n",
        "    else:\n",
        "        y2_test_pred_.append(0)\n",
        "metrics.precision_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BbcuuZdc3pI3",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.recall_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lkPdGhse3pI-",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.f1_score(test_data_labels, y2_test_pred_) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1Wrg5v6S3pJE",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tk3l_3Jc3pJI",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pkLLAYf23pJS",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "min_val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kQoiXhdGvFW",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewZT19MJGyOb",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZKFVTqfG2mK",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=500, input_dim=50, kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "for i in range(9):\n",
        "    model.add(Dense(units=500, kernel_initializer='he_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=100, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "min_epochs = 1\n",
        "min_val_loss = 1000\n",
        "for i in range(0,len(acc)):\n",
        "    if val_loss[i]<min_val_loss:\n",
        "      min_val_loss = val_loss[i]\n",
        "      min_epochs = i+1\n",
        "      \n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=min_epochs, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "scores = model.evaluate(x_test, y2_test, verbose=1)\n",
        "scores[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bANINkCw3w6d",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "y2_test_pred = model.predict(x_test,batch_size=32,verbose=0) #y2_test #ture\n",
        "y2_test_pred_ = []\n",
        "for i in range(0,len(y2_test_pred)):\n",
        "    if y2_test_pred[i]>=0.5:\n",
        "        y2_test_pred_.append(1)\n",
        "    else:\n",
        "        y2_test_pred_.append(0)\n",
        "metrics.precision_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iaiecEpq3w6n",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.recall_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ewoXAZyL3w6y",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.f1_score(test_data_labels, y2_test_pred_) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_LwGGnoQ3w63",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AzuG7hLo3w69",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5UpFDm3w3w7C",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhNfqyoIG6DS",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFgFEsp-G8m4",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFwi4uuQG_Op",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=500, input_dim=50, kernel_initializer='he_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "for i in range(9):\n",
        "    model.add(Dense(units=500, kernel_initializer='he_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=100, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "min_epochs = 1\n",
        "min_val_loss = 1000\n",
        "for i in range(0,len(acc)):\n",
        "    if val_loss[i]<min_val_loss:\n",
        "      min_val_loss = val_loss[i]\n",
        "      min_epochs = i+1\n",
        "      \n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=min_epochs, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "scores = model.evaluate(x_test, y2_test, verbose=1)\n",
        "scores[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yZxsmu45308s",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "y2_test_pred = model.predict(x_test,batch_size=32,verbose=0) #y2_test #ture\n",
        "y2_test_pred_ = []\n",
        "for i in range(0,len(y2_test_pred)):\n",
        "    if y2_test_pred[i]>=0.5:\n",
        "        y2_test_pred_.append(1)\n",
        "    else:\n",
        "        y2_test_pred_.append(0)\n",
        "metrics.precision_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QXZ2kY7y3081",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.recall_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RyG_yHZA3089",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.f1_score(test_data_labels, y2_test_pred_) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "inPD3Inx309E",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QEJ9T8kx309H",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ekdfPNO309M",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2m-osbBHBsQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6FE4e0mHENv",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZInaY1g_HGu4",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=500, input_dim=50, kernel_initializer='lecun_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('selu'))\n",
        "\n",
        "for i in range(9):\n",
        "    model.add(Dense(units=500, kernel_initializer='lecun_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('selu'))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=100, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "min_epochs = 1\n",
        "min_val_loss = 1000\n",
        "for i in range(0,len(acc)):\n",
        "    if val_loss[i]<min_val_loss:\n",
        "      min_val_loss = val_loss[i]\n",
        "      min_epochs = i+1\n",
        "      \n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=min_epochs, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "scores = model.evaluate(x_test, y2_test, verbose=1)\n",
        "scores[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FycI5ri534bp",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "y2_test_pred = model.predict(x_test,batch_size=32,verbose=0) #y2_test #ture\n",
        "y2_test_pred_ = []\n",
        "for i in range(0,len(y2_test_pred)):\n",
        "    if y2_test_pred[i]>=0.5:\n",
        "        y2_test_pred_.append(1)\n",
        "    else:\n",
        "        y2_test_pred_.append(0)\n",
        "metrics.precision_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BKB2SwsJ34by",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.recall_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9krB8nus34b2",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.f1_score(test_data_labels, y2_test_pred_) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QHOvFV1F34b8",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3J9eq5pu34cE",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mPaeYDtP34cJ",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4mMLvS4HJdl",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRFsXuQvHMdM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfUqPpjNHOyi",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=500, input_dim=50, kernel_initializer='lecun_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('selu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "for i in range(9):\n",
        "    model.add(Dense(units=500, kernel_initializer='lecun_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('selu'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=100, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "min_epochs = 1\n",
        "min_val_loss = 1000\n",
        "for i in range(0,len(acc)):\n",
        "    if val_loss[i]<min_val_loss:\n",
        "      min_val_loss = val_loss[i]\n",
        "      min_epochs = i+1\n",
        "      \n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=min_epochs, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "scores = model.evaluate(x_test, y2_test, verbose=1)\n",
        "scores[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vpWLoVoX36O2",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "y2_test_pred = model.predict(x_test,batch_size=32,verbose=0) #y2_test #ture\n",
        "y2_test_pred_ = []\n",
        "for i in range(0,len(y2_test_pred)):\n",
        "    if y2_test_pred[i]>=0.5:\n",
        "        y2_test_pred_.append(1)\n",
        "    else:\n",
        "        y2_test_pred_.append(0)\n",
        "metrics.precision_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rxnQaRqY36O8",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.recall_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "diPEZeFy36PB",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.f1_score(test_data_labels, y2_test_pred_) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OJql_4NC36PH",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vbeuu3lc36PK",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-PIras0B36PR",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqpt3edkHRFG",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oOO6ER9HTOR",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "it59uzhJHWWm",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=500, input_dim=50, kernel_initializer='lecun_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('swish'))\n",
        "\n",
        "for i in range(9):\n",
        "    model.add(Dense(units=500, kernel_initializer='lecun_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('swish'))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=100, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "min_epochs = 1\n",
        "min_val_loss = 1000\n",
        "for i in range(0,len(acc)):\n",
        "    if val_loss[i]<min_val_loss:\n",
        "      min_val_loss = val_loss[i]\n",
        "      min_epochs = i+1\n",
        "      \n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=min_epochs, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "scores = model.evaluate(x_test, y2_test, verbose=1)\n",
        "scores[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r6f4tiF338Tb",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "y2_test_pred = model.predict(x_test,batch_size=32,verbose=0) #y2_test #ture\n",
        "y2_test_pred_ = []\n",
        "for i in range(0,len(y2_test_pred)):\n",
        "    if y2_test_pred[i]>=0.5:\n",
        "        y2_test_pred_.append(1)\n",
        "    else:\n",
        "        y2_test_pred_.append(0)\n",
        "metrics.precision_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5cicN_a138Tk",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.recall_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bJHVHvPL38T3",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.f1_score(test_data_labels, y2_test_pred_) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i31l3ATd38UC",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RzQNa9-w38UJ",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mFOPby3v38UQ",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAUoFUftHYkB",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7K7G0abHbv8",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsmbzrcZHkl6",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(units=500, input_dim=50, kernel_initializer='lecun_normal'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('swish'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "for i in range(9):\n",
        "    model.add(Dense(units=500, kernel_initializer='lecun_normal'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('swish'))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=100, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "min_epochs = 1\n",
        "min_val_loss = 1000\n",
        "for i in range(0,len(acc)):\n",
        "    if val_loss[i]<min_val_loss:\n",
        "      min_val_loss = val_loss[i]\n",
        "      min_epochs = i+1\n",
        "      \n",
        "history = model.fit(x_train, y2_train, batch_size=32, validation_split=0.2, epochs=min_epochs, callbacks=[earlyStopping, learning_rate_reduction])\n",
        "\n",
        "scores = model.evaluate(x_test, y2_test, verbose=1)\n",
        "scores[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YpWoFmoM39zF",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "y2_test_pred = model.predict(x_test,batch_size=32,verbose=0) #y2_test #ture\n",
        "y2_test_pred_ = []\n",
        "for i in range(0,len(y2_test_pred)):\n",
        "    if y2_test_pred[i]>=0.5:\n",
        "        y2_test_pred_.append(1)\n",
        "    else:\n",
        "        y2_test_pred_.append(0)\n",
        "metrics.precision_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i5vY_dSp39zM",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.recall_score(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E_RWBUJV39zV",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "metrics.f1_score(test_data_labels, y2_test_pred_) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ecj8WnhJ39ze",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(test_data_labels, y2_test_pred_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n0INnODv39zk",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TLrZVG1S39zr",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "min_val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAg9hT4EHqwI",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPuSgDkIHtIn",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation acc')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('ACC')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}